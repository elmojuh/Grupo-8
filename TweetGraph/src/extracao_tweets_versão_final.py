# -*- coding: utf-8 -*-
"""Extracao Tweets - Versão Final

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OC63tPO7Oa-e2kJjOQZo_LhR1zDTe1eP
"""

# Instalando bibliotecas
#pip install --upgrade tweepy
#pip install --upgrade networkx

# Importando bibliotecas usadas
import tweepy as tw
import pytz
import datetime
import pandas as pd
import networkx as nx

#pd.set_option('display.max_colwidth', None)


class GrafoTwitter:
    usuarios = []
    grafo = None
    tweetsContent = ''

    #Construtor
    def __init__(self, query, data_inicio, data_fim, client=None):
        self.query = query
        self.data_inicio = data_inicio
        self.data_fim = data_fim
        self.client = None,
        self.grafo = nx.DiGraph()

    # Autenticar usando chave e retorna objeto da API para manipulacao
    def autenticarAPI(self, bearer_token):
        self.client = tw.Client(bearer_token)
        print(self.client)

    # Formatar a data de acordo com o necessário na API
    def converteData(self, data):
        # O formato de datetime esperado pela API é "2023-1-1 12:00:00"
        local_time = pytz.timezone("America/Sao_Paulo")
        utc_data = local_time.localize(datetime.datetime.strptime(
            data, "%Y-%m-%d %H:%M:%S"),
                                       is_dst=None).astimezone(pytz.utc)
        dtformat = '%Y-%m-%dT%H:%M:%SZ'
        time = datetime.datetime.utcnow()
        return utc_data.strftime(dtformat)

    # Extrair 100 tweets (limite da API)
    def extrairTweets(self):
        if (self.contarTweetsQuery() == True):
            self.tweetsContent = self.client.search_recent_tweets(
                self.query,
                max_results=100,
                start_time=self.converteData(self.data_inicio),
                end_time=self.converteData(self.data_fim),
                user_fields=['id', 'username'],
                expansions=['author_id', 'entities.mentions.username'],
                tweet_fields=['created_at'])
        else:
            return print('É necessário tentar pesquisa com menor range')

    # Contar Tweets disponiveis na query pesquisada.
    def contarTweetsQuery(self):
        #Importante pois a cada 15 minutos há um limite de 450 request, ou seja, 45000 tweets podem ser extraidos a cada 15 minutos.
        contagem = self.client.get_recent_tweets_count(
            self.query,
            start_time=self.converteData(self.data_inicio),
            end_time=self.converteData(self.data_fim),
            granularity="day")
        print('Quantidade de Tweets:' +
              str(contagem.meta['total_tweet_count']))
        #return contagem.meta['total_tweet_count']
        if (contagem.meta['total_tweet_count'] < 45000):
            return True
        else:
            return False

    def gravarDicionario(self):
        for user in self.tweetsContent.includes['users']:
            users_dict = {}
            users_dict[0] = user['id']
            users_dict[1] = user['username']
            self.usuarios.append(users_dict)

    def criarGrafo(self):
        if (self.contarTweetsQuery() == True):
            self.gravarDicionario()
            for tweet in self.tweetsContent.data:
                if "entities" in tweet:
                    for mencao in tweet.entities['mentions']:
                        # Buscando o user_name do autor do Tweet
                        username_autor_tweet = list(
                            filter(lambda usuario: usuario[0] == tweet.author_id,
                                self.usuarios))[0][1]
                        # Criando uma aresta do autor Tweet para o(s) usuário(s) citado(s)
                        self.grafo.add_edge(username_autor_tweet,
                                            mencao['username'])
            # Exportando o grafo para um arquivo

            if ("next_token" in self.tweetsContent.meta):
                self.fazerPaginacao()
            nx.write_graphml_lxml(
                self.grafo,
                "./grafo_extracao_{0}.graphml".format(self.query.split(' ', 1)[0]))
            print('Grafo criado')
        else:
            print('Numero de tweets excede o limite, tente range menor.')

    def fazerPaginacao(self):
        while ("next_token" in self.tweetsContent.meta):
            self.tweetsContent = self.client.search_recent_tweets(
                self.query,
                next_token=self.tweetsContent.meta['next_token'],
                max_results=100,
                start_time=self.converteData(self.data_inicio),
                end_time=self.converteData(self.data_fim),
                user_fields=['id', 'username'],
                expansions=['author_id', 'entities.mentions.username'],
                tweet_fields=['created_at'])

        self.gravarDicionario()
        # Gravando a ID e username dos autores dos Tweets
        for user in self.tweetsContent.includes['users']:
            users_dict = {}
            users_dict[0] = user['id']
            users_dict[1] = user['username']
            self.usuarios.append(users_dict)

        for tweet in self.tweetsContent.data:
            if "entities" in tweet:
                for mencao in tweet.entities['mentions']:
                    # Gravando a ID e username dos autores dos Tweets
                    username_autor_tweet = list(
                        filter(lambda usuario: usuario[0] == tweet.author_id,
                               self.usuarios))[0][1]
                    # Criando uma aresta do autor Tweet para o(s) usuário(s) citado(s)
                    self.grafo.add_edge(username_autor_tweet,
                                        mencao['username'])


# Main Script para executar o grafo para o Lula e o para o Bolsonaro
if __name__ == "__main__":
    print('\n Grafo Lula \n')
    grafinho = GrafoTwitter(
        query='Lula  lang:pt',
        data_inicio='2023-01-08 23:00:00',
        data_fim='2023-01-08 23:10:00'        
    )
    grafinho.autenticarAPI(bearer_token=
        'AAAAAAAAAAAAAAAAAAAAAKtckwEAAAAAYV8r7pZHTOzX%2F1ZH7dywUUELKxU%3DfuB1CZ6BYXp8S0Jjf2md95jIifYwCLrc875I0Zt9kp5cNOsd6S')
    grafinho.extrairTweets()
    grafinho.contarTweetsQuery()
    grafinho.criarGrafo()

    print('\n Grafo Bolsonaro \n')
    grafinho2 = GrafoTwitter(
        query='Bolsonaro  lang:pt',
        data_inicio='2023-01-08 23:00:00',
        data_fim='2023-01-08 23:10:00'
        
    )
    grafinho2.autenticarAPI(bearer_token=
        'AAAAAAAAAAAAAAAAAAAAAKtckwEAAAAAYV8r7pZHTOzX%2F1ZH7dywUUELKxU%3DfuB1CZ6BYXp8S0Jjf2md95jIifYwCLrc875I0Zt9kp5cNOsd6S')
    grafinho2.extrairTweets()
    grafinho2.contarTweetsQuery()
    grafinho2.criarGrafo()
