{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pw2_fd17wUU_"
      },
      "outputs": [],
      "source": [
        "# Instalando bibliotecas \n",
        "!pip install --upgrade tweepy\n",
        "!pip install snscrape\n",
        "!pip install --upgrade networkx"
      ],
      "id": "Pw2_fd17wUU_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fcd1fa7"
      },
      "outputs": [],
      "source": [
        "# Importando biblioteca de acesso a API do Twitter\n",
        "import tweepy as tw\n",
        "#tw.__version__   aaa sb\n",
        "import pytz\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "id": "2fcd1fa7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3s3SjU7FjEm"
      },
      "outputs": [],
      "source": [
        "class GrafoTwitter:\n",
        "  dados = []\n",
        "  usuarios = []\n",
        "  grafo = None\n",
        "\n",
        "  #Construtor\n",
        "  def __init__(self, query, data_inicio, data_fim,bearer_token,client=None):\n",
        "    self.query = query\n",
        "    self.data_inicio = data_inicio\n",
        "    self.data_fim = data_fim\n",
        "    self.bearer_token = bearer_token\n",
        "    self.client = None,\n",
        "    self.grafo = nx.DiGraph()\n",
        "  \n",
        "  # Autenticar usando chave e retorna objeto da API para manipulacao\n",
        "  def autenticarAPI(self):\n",
        "    self.client = tw.Client(self.bearer_token)\n",
        "    print(self.client)\n",
        "    \n",
        "\n",
        "  # Formatar a data de acordo com o necessário na API\n",
        "  def converteData(self,data):\n",
        "    # O formato de datetime esperado pela API é \"2023-1-1 12:00:00\"\n",
        "    local_time = pytz.timezone(\"America/Sao_Paulo\")\n",
        "    utc_data = local_time.localize(datetime.datetime.strptime(data, \"%Y-%m-%d %H:%M:%S\"), is_dst=None).astimezone(pytz.utc)\n",
        "    dtformat = '%Y-%m-%dT%H:%M:%SZ'\n",
        "    time = datetime.datetime.utcnow()\n",
        "    return utc_data.strftime(dtformat)\n",
        "  \n",
        "  # Extrair 100 tweets (limite da API)\n",
        "  def extrairTweets(self):\n",
        "    self.tweetsContent = self.client.search_recent_tweets(self.query, max_results=100,start_time= self.converteData(self.data_inicio), end_time= self.converteData(self.data_fim),\n",
        "                                       user_fields=['id','username'], expansions=['author_id','entities.mentions.username'], tweet_fields=['created_at'])\n",
        "    self.df_tweets_extraidos = pd.DataFrame.from_dict(self.tweetsContent.data)\n",
        "    print(self.df_tweets_extraidos.head(3))\n",
        "\n",
        "  # Contar Tweets disponiveis na query pesquisada. \n",
        "  def contarTweetsQuery(self):\n",
        "    #Importante pois a cada 15 minutos há um limite de 450 request, ou seja, 45000 tweets podem ser extraidos a cada 15 minutos.\n",
        "    contagem = self.client.get_recent_tweets_count(self.query, start_time=self.converteData(self.data_inicio), end_time=self.converteData(self.data_fim), granularity=\"day\")\n",
        "    #print('Quantidade de Tweets:' + str(contagem.meta['total_tweet_count']))\n",
        "    return contagem.meta['total_tweet_count']\n",
        "\n",
        "  def gravarDicionario(self):\n",
        "    for user in self.tweetsContent.includes['users']:\n",
        "      users_dict = {}\n",
        "      users_dict[0] = user['id']\n",
        "      users_dict[1] = user['username']\n",
        "      self.usuarios.append(users_dict)\n",
        "\n",
        "  def criarGrafo(self):\n",
        "    self.gravarDicionario()\n",
        "    for tweet in self.tweetsContent.data:\n",
        "        self.dados.append([tweet.author_id, tweet.created_at, tweet.edit_history_tweet_ids, tweet.id, tweet.text])\n",
        "        if \"entities\" in tweet:\n",
        "          for mencao in tweet.entities['mentions']:            \n",
        "              # Buscando o user_name do autor do Tweet\n",
        "              username_autor_tweet = list(filter(lambda usuario: usuario[0] == tweet.author_id, self.usuarios))[0][1]\n",
        "              # Criando uma aresta do autor Tweet para o(s) usuário(s) citado(s)\n",
        "              self.grafo.add_edge(username_autor_tweet,mencao['username'])\n",
        "    # Exportando o grafo para um arquivo            \n",
        "    \n",
        "    if (\"next_token\" in self.tweetsContent.meta):\n",
        "      self.fazerPaginacao()\n",
        "    nx.write_graphml_lxml(self.grafo, \"grafo_extracao_{0}.graphml\".format(self.query.split(' ',1)[0])) \n",
        "\n",
        "  def fazerPaginacao(self):\n",
        "    while (\"next_token\" in self.tweetsContent.meta):\n",
        "       self.tweetsContent = self.client.search_recent_tweets(self.query, next_token=self.tweetsContent.meta['next_token'], max_results=100,\n",
        "                                           start_time=self.converteData(self.data_inicio), end_time= self.converteData(self.data_fim),user_fields=['id','username'], \n",
        "                                           expansions=['author_id','entities.mentions.username'], tweet_fields=['created_at'])\n",
        "    \n",
        "    self.gravarDicionario()\n",
        "    # Gravando a ID e username dos autores dos Tweets\n",
        "    for user in self.tweetsContent.includes['users']:\n",
        "        users_dict = {}\n",
        "        users_dict[0] = user['id']\n",
        "        users_dict[1] = user['username']\n",
        "        self.usuarios.append(users_dict)\n",
        "    \n",
        "    for tweet in self.tweetsContent.data:\n",
        "        self.dados.append([tweet.author_id, tweet.created_at, tweet.edit_history_tweet_ids, tweet.id, tweet.text])\n",
        "        if \"entities\" in tweet:\n",
        "          for mencao in tweet.entities['mentions']:            \n",
        "              # Gravando a ID e username dos autores dos Tweets\n",
        "              username_autor_tweet = list(filter(lambda usuario: usuario[0] == tweet.author_id, self.usuarios))[0][1]\n",
        "              # Criando uma aresta do autor Tweet para o(s) usuário(s) citado(s)\n",
        "              self.grafo.add_edge(username_autor_tweet,mencao['username'])\n",
        "\n",
        "\n",
        "    "
      ],
      "id": "n3s3SjU7FjEm"
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Script para executar o grafo para o Lula\n",
        "if __name__ == \"__main__\":\n",
        "  grafinho = GrafoTwitter(query='Lula  lang:pt', data_inicio='2023-01-08 23:05:00', data_fim='2023-01-08 23:10:00',bearer_token='AAAAAAAAAAAAAAAAAAAAAKtckwEAAAAAYV8r7pZHTOzX%2F1ZH7dywUUELKxU%3DfuB1CZ6BYXp8S0Jjf2md95jIifYwCLrc875I0Zt9kp5cNOsd6S')\n",
        "  grafinho.autenticarAPI()\n",
        "  grafinho.extrairTweets()\n",
        "  grafinho.contarTweetsQuery()\n",
        "  grafinho.criarGrafo()"
      ],
      "metadata": {
        "id": "O9M2xANbe1zh"
      },
      "id": "O9M2xANbe1zh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTITlVEcFm9l"
      },
      "outputs": [],
      "source": [
        "# Main Script para executar o grafo para o Bolsonaro\n",
        "if __name__ == \"__main__\":    \n",
        "  grafinho = GrafoTwitter(query='Bolsonaro  lang:pt', data_inicio='2023-01-08 23:05:00', data_fim='2023-01-08 23:10:00',bearer_token='AAAAAAAAAAAAAAAAAAAAAKtckwEAAAAAYV8r7pZHTOzX%2F1ZH7dywUUELKxU%3DfuB1CZ6BYXp8S0Jjf2md95jIifYwCLrc875I0Zt9kp5cNOsd6S')\n",
        "  grafinho.autenticarAPI()\n",
        "  grafinho.extrairTweets()\n",
        "  grafinho.contarTweetsQuery()\n",
        "  grafinho.criarGrafo()"
      ],
      "id": "CTITlVEcFm9l"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
